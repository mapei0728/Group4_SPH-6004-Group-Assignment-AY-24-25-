{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0241770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Standard Libraries \n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from typing import Dict, List\n",
    "\n",
    "# Third-Party Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Evaluation (sklearn) \n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1ced8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"mimic_multimodal_dataset.npz\", allow_pickle=True)\n",
    "embeddings = data[\"embeddings\"]\n",
    "labels = data[\"labels\"]\n",
    "texts = data[\"texts\"]\n",
    "subject_ids = data[\"subject_ids\"]\n",
    "study_ids = data[\"study_ids\"]\n",
    "\n",
    "# Get number of samples\n",
    "N = len(embeddings)\n",
    "indices = np.random.RandomState(seed=42).permutation(N)\n",
    "\n",
    "# Compute split sizes\n",
    "n_train = int(0.8 * N)\n",
    "n_valid = int(0.1 * N)\n",
    "n_test = N - n_train - n_valid  # The rest goes to test\n",
    "\n",
    "# Split indices\n",
    "train_idx = indices[:n_train]\n",
    "valid_idx = indices[n_train:n_train + n_valid]\n",
    "test_idx  = indices[n_train + n_valid:]\n",
    "\n",
    "# Split data based on indices\n",
    "train_set = {\n",
    "    \"embeddings\": embeddings[train_idx],\n",
    "    \"labels\": labels[train_idx],\n",
    "    \"texts\": texts[train_idx],\n",
    "    \"subject_ids\": subject_ids[train_idx],\n",
    "    \"study_ids\": study_ids[train_idx]\n",
    "}\n",
    "\n",
    "valid_set = {\n",
    "    \"embeddings\": embeddings[valid_idx],\n",
    "    \"labels\": labels[valid_idx],\n",
    "    \"texts\": texts[valid_idx],\n",
    "    \"subject_ids\": subject_ids[valid_idx],\n",
    "    \"study_ids\": study_ids[valid_idx]\n",
    "}\n",
    "\n",
    "test_set = {\n",
    "    \"embeddings\": embeddings[test_idx],\n",
    "    \"labels\": labels[test_idx],\n",
    "    \"texts\": texts[test_idx],\n",
    "    \"subject_ids\": subject_ids[test_idx],\n",
    "    \"study_ids\": study_ids[test_idx]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df64476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all pathologies list\n",
    "pathologies = [\n",
    "        \"Enlarged Cardiomediastinum\",\n",
    "        \"Cardiomegaly\",\n",
    "        \"Lung Opacity\",\n",
    "        \"Lung Lesion\",\n",
    "        \"Edema\",\n",
    "        \"Consolidation\",\n",
    "        \"Pneumonia\",\n",
    "        \"Atelectasis\",\n",
    "        \"Pneumothorax\",\n",
    "        \"Pleural Effusion\",\n",
    "        \"Pleural Other\",\n",
    "        \"Fracture\",\n",
    "        \"Support Devices\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87e917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, data_dict, tokenizer, max_length=128):\n",
    "        self.embeddings = data_dict[\"embeddings\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        self.texts = data_dict[\"texts\"]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_embedding = torch.tensor(self.embeddings[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        # Tokenize report text using BERT tokenizer\n",
    "        text = str(self.texts[idx])\n",
    "        encoded = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"image\": image_embedding,\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),  # [seq_len]\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),  # [seq_len]\n",
    "            \"label\": label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8144a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfe2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create datasets\n",
    "def get_single_label_dataset(data_dict, label_index):\n",
    "    new_dict = data_dict.copy()\n",
    "    new_dict[\"labels\"] = data_dict[\"labels\"][:, label_index:label_index+1]  # shape [N, 1]\n",
    "    return MultimodalDataset(new_dict, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b5ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings shape: (36502, 1376)\n",
      "labels shape: (36502, 13)\n",
      "texts length: 36502\n",
      "subject_ids shape: (36502,)\n",
      "study_ids shape: (36502,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of each component (number of samples & dimensions)\n",
    "print(\"embeddings shape:\", train_set[\"embeddings\"].shape)      # (N, 1376)\n",
    "print(\"labels shape:\", train_set[\"labels\"].shape)              # (N, 13)\n",
    "print(\"texts length:\", len(train_set[\"texts\"]))                # N\n",
    "print(\"subject_ids shape:\", train_set[\"subject_ids\"].shape)    # (N,)\n",
    "print(\"study_ids shape:\", train_set[\"study_ids\"].shape)        # (N,)\n",
    "# [B, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d9990d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample index: 10\n",
      "Embedding vector (first 5 dims): [-0.10261969 -0.9120668   0.88922745 -1.6479412  -0.41724488]\n",
      "Label vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Text sample:                                  FINAL REPORT\n",
      " EXAMINATION:  CHEST RADIOGRAPHS\n",
      " \n",
      " INDICATION:  Chest pain.\n",
      " \n",
      " TECHNIQUE:  Chest, PA and lateral.\n",
      " \n",
      " COMPARISON:  None.\n",
      " \n",
      " FINDINGS: \n",
      " \n",
      " The heart is normal in size. There is patchy calcification along the aortic\n",
      " arch. The lungs appear clear. There are no pleural effusions or pneumothorax.\n",
      " \n",
      " IMPRESSION: \n",
      " \n",
      " No evidence of acute cardiopulmonary disease.\n",
      "\n",
      "Subject ID: 19346252\n",
      "Study ID: 51125476\n"
     ]
    }
   ],
   "source": [
    "i = 10 \n",
    "\n",
    "print(\"\\nSample index:\", i)\n",
    "print(\"Embedding vector (first 5 dims):\", train_set[\"embeddings\"][i][:5])\n",
    "print(\"Label vector:\", train_set[\"labels\"][i])\n",
    "print(\"Text sample:\", train_set[\"texts\"][i])\n",
    "print(\"Subject ID:\", train_set[\"subject_ids\"][i])\n",
    "print(\"Study ID:\", train_set[\"study_ids\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6487f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAsymmetricLoss(nn.Module):\n",
    "    def __init__(self, gamma_pos=0.0, gamma_neg=4.0, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        mask = ~torch.isnan(labels)\n",
    "        labels = torch.where(mask, labels, torch.zeros_like(labels))  # Fill NaN for safety\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = torch.clamp(probs, self.eps, 1 - self.eps)\n",
    "\n",
    "        pos_loss = labels * ((1 - probs) ** self.gamma_pos) * torch.log(probs)\n",
    "        neg_loss = (1 - labels) * (probs ** self.gamma_neg) * torch.log(1 - probs)\n",
    "\n",
    "        loss = - (pos_loss + neg_loss)\n",
    "        loss = loss[mask]  # apply mask\n",
    "\n",
    "        if loss.numel() == 0:\n",
    "            return torch.tensor(0.0, device=logits.device, requires_grad=True)\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd88841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalFusionModel(nn.Module):\n",
    "    def __init__(self, image_dim=1376, text_dim=768, hidden_dim=512, num_labels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Project image and text to shared hidden space\n",
    "        self.img_proj = nn.Linear(image_dim, hidden_dim)\n",
    "        self.txt_proj = nn.Linear(text_dim, hidden_dim)\n",
    "\n",
    "        # Transformer encoder for cross-modal fusion\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=8,\n",
    "            dim_feedforward=1024,\n",
    "            dropout=0.1,\n",
    "            batch_first=True,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.fusion_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "\n",
    "        # Multi-label classification head\n",
    "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
    "\n",
    "    def forward(self, image_emb, text_emb):\n",
    "        \"\"\"\n",
    "        image_emb: Tensor of shape [B, image_dim]\n",
    "        text_emb: Tensor of shape [B, text_dim] (e.g., BERT CLS token)\n",
    "        \"\"\"\n",
    "        # Project both modalities into common hidden space\n",
    "        img_feat = self.img_proj(image_emb)   # [B, hidden_dim]\n",
    "        txt_feat = self.txt_proj(text_emb)    # [B, hidden_dim]\n",
    "\n",
    "        # Stack: [B, 2, hidden_dim] for transformer input\n",
    "        fused = torch.stack([img_feat, txt_feat], dim=1)\n",
    "\n",
    "        # Transformer-based fusion\n",
    "        fused_out = self.fusion_encoder(fused)  # [B, 2, hidden_dim]\n",
    "\n",
    "        # Mean pooling over modalities\n",
    "        fusion_repr = fused_out.mean(dim=1)     # [B, hidden_dim]\n",
    "\n",
    "        # Output: raw logits (use sigmoid + BCE or ASL externally)\n",
    "        logits = self.classifier(fusion_repr)   # [B, num_labels]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8cdde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ClinicalBERT model\n",
    "text_encoder = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\").to(device)\n",
    "\n",
    "# Initialize the multimodal model\n",
    "model = MultiModalFusionModel().to(device)\n",
    "\n",
    "# Forward pass example\n",
    "for batch in train_loader:\n",
    "    image = batch[\"image\"].to(device)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_feat = text_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        ).last_hidden_state[:, 0, :]  # [B, 768]\n",
    "\n",
    "    outputs = model(image, text_feat)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4086acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MaskedAsymmetricLoss(gamma_pos=0.0, gamma_neg=4.0)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "493bb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, text_encoder, device):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            image = batch[\"image\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "\n",
    "            text_feat = text_encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "            logits = model(image, text_feat)\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "\n",
    "            # Flatten & mask NaNs for evaluation\n",
    "            mask = ~torch.isnan(label)\n",
    "            all_preds.append(preds[mask].cpu().numpy())\n",
    "            all_targets.append(label[mask].cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_targets)\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "\n",
    "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6bd0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, text_encoder, loss_fn, optimizer, device, num_epochs=1):\n",
    "    model.to(device)\n",
    "    text_encoder.to(device)\n",
    "    text_encoder.eval()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        skipped_batches = 0\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        for batch in loop:\n",
    "            image = batch[\"image\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "\n",
    "            # Skip batches where all labels are NaN\n",
    "            if torch.isnan(label).all():\n",
    "                print(\"Skipping batch with all NaN labels.\")\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "\n",
    "            # Extract text features\n",
    "            with torch.no_grad():\n",
    "                text_feat = text_encoder(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                ).last_hidden_state[:, 0, :]  # [CLS] token\n",
    "\n",
    "            logits = model(image, text_feat)\n",
    "            loss = loss_fn(logits, label)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(\"Skipping batch due to NaN loss.\")\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / (len(train_loader) - skipped_batches + 1e-6)\n",
    "        print(f\"\\n Epoch {epoch+1} completed. Avg Loss = {avg_loss:.4f} | Skipped Batches: {skipped_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9434eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = train_set[\"labels\"].shape[1]\n",
    "\n",
    "def get_single_label_dataset(data_dict, label_index):\n",
    "    new_dict = data_dict.copy()\n",
    "    new_dict[\"labels\"] = data_dict[\"labels\"][:, label_index:label_index+1]  # Shape: [N, 1]\n",
    "    return MultimodalDataset(new_dict, tokenizer)\n",
    "\n",
    "for i in range(num_labels):\n",
    "    label_name = pathologies[i]\n",
    "    print(f\"\\n Training model for label {i}: {label_name}\")\n",
    "\n",
    "    # Build datasets for this label only\n",
    "    train_dataset = get_single_label_dataset(train_set, i)\n",
    "    valid_dataset = get_single_label_dataset(valid_set, i)\n",
    "    test_dataset  = get_single_label_dataset(test_set, i)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Model, optimizer, and loss function\n",
    "    model = MultiModalFusionModel(num_labels=1).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    criterion = MaskedAsymmetricLoss(gamma_pos=0.0, gamma_neg=4.0)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        text_encoder=text_encoder,\n",
    "        loss_fn=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=1\n",
    "    )\n",
    "\n",
    "    # Save the model for this label\n",
    "    torch.save(model.state_dict(), f\"model_ovr_label{i}_{label_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1043518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get(report, class_label, metric):\n",
    "    \"\"\"\n",
    "    Safely extract a specific class or average metric.\n",
    "    - For class_label as 0 or 1, try multiple key formats;\n",
    "    - For average entries like 'macro avg', lookup directly.\n",
    "    \"\"\"\n",
    "    if isinstance(class_label, (int, float)):\n",
    "        keys_to_try = [class_label, str(class_label), f\"{float(class_label):.1f}\"]\n",
    "    else:\n",
    "        keys_to_try = [class_label]\n",
    "\n",
    "    for key in keys_to_try:\n",
    "        if key in report and metric in report[key]:\n",
    "            return report[key][metric]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def evaluate_full_report(model, dataloader, text_encoder, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    text_encoder.eval()\n",
    "    text_encoder.to(device)\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            image = batch[\"image\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            y = batch[\"label\"].to(device)\n",
    "\n",
    "            # BERT text embedding\n",
    "            text_feat = text_encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "            logits = model(image, text_feat)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).float()\n",
    "\n",
    "            y_np = y.cpu().numpy()\n",
    "            preds_np = preds.cpu().numpy()\n",
    "\n",
    "            # Mask: remove rows with NaN in label\n",
    "            mask = ~np.isnan(y_np).flatten()\n",
    "            y_clean = y_np[mask]\n",
    "            preds_clean = preds_np[mask]\n",
    "\n",
    "            all_labels.extend(y_clean)\n",
    "            all_preds.extend(preds_clean)\n",
    "\n",
    "\n",
    "    accuracy = (np.array(all_labels) == np.array(all_preds)).mean()\n",
    "\n",
    "    return classification_report(all_labels, all_preds, digits=4, output_dict=True), accuracy\n",
    "\n",
    "\n",
    "# Collect reports for all labels\n",
    "report_dict = {}\n",
    "\n",
    "for i, label_name in enumerate(label_names):\n",
    "    print(\"=\" * 30)\n",
    "    print(f\" Test Evaluation Report for: {label_name}\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    # Use multimodal test dataset for current label\n",
    "    test_dataset = get_single_label_dataset(test_set, i)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Load model\n",
    "    model = MultiModalFusionModel(num_labels=1)\n",
    "    model.load_state_dict(torch.load(f\"model_ovr_label{i}_{label_name}.pt\"))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Evaluate\n",
    "    report, acc = evaluate_full_report(model, test_loader, text_encoder, device)\n",
    "\n",
    "    report_dict[label_name] = {\n",
    "        'precision_0': safe_get(report, 0, 'precision'),\n",
    "        'recall_0': safe_get(report, 0, 'recall'),\n",
    "        'f1-score_0': safe_get(report, 0, 'f1-score'),\n",
    "\n",
    "        'precision_1': safe_get(report, 1, 'precision'),\n",
    "        'recall_1': safe_get(report, 1, 'recall'),\n",
    "        'f1-score_1': safe_get(report, 1, 'f1-score'),\n",
    "\n",
    "        'precision': safe_get(report, 'macro avg', 'precision'),\n",
    "        'recall': safe_get(report, 'macro avg', 'recall'),\n",
    "        'f1-score': safe_get(report, 'macro avg', 'f1-score'),\n",
    "        'support': safe_get(report, 'macro avg', 'support'),\n",
    "\n",
    "        'accuracy': acc\n",
    "    }\n",
    "\n",
    "# Save as DataFrame\n",
    "df = pd.DataFrame(report_dict)\n",
    "df.index.name = \"Metric\"\n",
    "df = df.round(4)\n",
    "df.to_csv(\"test_metrics_per_label.csv\")\n",
    "print(\"\\n Saved report with accuracy to: test_metrics_per_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49b0aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      " Test Metrics for: Enlarged Cardiomediastinum\n",
      "========================================\n",
      "AUC Score:              0.9368\n",
      "Average Precision (AP): 0.5858\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Cardiomegaly\n",
      "========================================\n",
      "AUC Score:              0.9338\n",
      "Average Precision (AP): 0.6136\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Lung Opacity\n",
      "========================================\n",
      "AUC Score:              0.9426\n",
      "Average Precision (AP): 0.3359\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Lung Lesion\n",
      "========================================\n",
      "AUC Score:              0.9596\n",
      "Average Precision (AP): 0.4967\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Edema\n",
      "========================================\n",
      "AUC Score:              0.8788\n",
      "Average Precision (AP): 0.1608\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Consolidation\n",
      "========================================\n",
      "AUC Score:              0.9383\n",
      "Average Precision (AP): 0.4092\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Pneumonia\n",
      "========================================\n",
      "AUC Score:              0.9438\n",
      "Average Precision (AP): 0.3990\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Atelectasis\n",
      "========================================\n",
      "AUC Score:              0.9309\n",
      "Average Precision (AP): 0.6275\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Pneumothorax\n",
      "========================================\n",
      "AUC Score:              0.9563\n",
      "Average Precision (AP): 0.7024\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Pleural Effusion\n",
      "========================================\n",
      "AUC Score:              0.9276\n",
      "Average Precision (AP): 0.2040\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Pleural Other\n",
      "========================================\n",
      "AUC Score:              0.9166\n",
      "Average Precision (AP): 0.4464\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Fracture\n",
      "========================================\n",
      "AUC Score:              0.9289\n",
      "Average Precision (AP): 0.2492\n",
      "\n",
      "========================================\n",
      " Test Metrics for: Support Devices\n",
      "========================================\n",
      "AUC Score:              0.9360\n",
      "Average Precision (AP): 0.5098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names =  [\n",
    "    \"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\", \"Lung Lesion\",\n",
    "    \"Edema\", \"Consolidation\", \"Pneumonia\", \"Atelectasis\",\n",
    "    \"Pneumothorax\", \"Pleural Effusion\", \"Pleural Other\", \"Fracture\", \"Support Devices\"\n",
    "]\n",
    "\n",
    "def evaluate_auc_ap(model, dataloader, text_encoder, device):\n",
    "    model.eval()\n",
    "    text_encoder.eval()\n",
    "    model.to(device)\n",
    "    text_encoder.to(device)\n",
    "\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            image = batch[\"image\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            y = batch[\"label\"].to(device).squeeze()\n",
    "\n",
    "            # Text embedding\n",
    "            text_feat = text_encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "            logits = model(image, text_feat).squeeze()\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "    # Clean\n",
    "    y_np = np.array(all_targets)\n",
    "    probs_np = np.array(all_probs)\n",
    "    mask = ~np.isnan(y_np)\n",
    "    y_np = y_np[mask]\n",
    "    probs_np = probs_np[mask]\n",
    "\n",
    "    # Handle edge case: only one class present\n",
    "    if len(np.unique(y_np)) < 2:\n",
    "        print(\"  Skipping label — only one class present in y_true.\")\n",
    "        return float('nan'), float('nan')\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_np, probs_np)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    try:\n",
    "        ap = average_precision_score(y_np, probs_np)\n",
    "    except ValueError:\n",
    "        ap = float('nan')\n",
    "\n",
    "    return auc, ap\n",
    "\n",
    "\n",
    "for i, label_name in enumerate(label_names):\n",
    "    print(\"=\" * 40)\n",
    "    print(f\" Test Metrics for: {label_name}\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # 1. Load test dataset (multimodal version)\n",
    "    test_dataset = get_single_label_dataset(test_set, i)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 2. Load trained model\n",
    "    model = MultiModalFusionModel(num_labels=1)\n",
    "    model.load_state_dict(torch.load(f\"model_ovr_label{i}_{label_name}.pt\"))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 3. Evaluate AUC and AP\n",
    "    auc, ap = evaluate_auc_ap(model, test_loader, text_encoder, device)\n",
    "    print(f\"AUC Score:              {auc:.4f}\")\n",
    "    print(f\"Average Precision (AP): {ap:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
