{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df706026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(embedding_path):\n",
    "    raw_dataset = tf.data.TFRecordDataset([embedding_path])\n",
    "    for raw_record in raw_dataset.take(1):\n",
    "      example = tf.train.Example()\n",
    "      example.ParseFromString(raw_record.numpy())\n",
    "      embedding_feature = example.features.feature['embedding']\n",
    "      embedding_values = embedding_feature.float_list.value\n",
    "    return torch.tensor(embedding_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4490aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIMIC_Embed_Dataset(Dataset):\n",
    "\n",
    "    pathologies = [\n",
    "        \"Enlarged Cardiomediastinum\",\n",
    "        \"Cardiomegaly\",\n",
    "        \"Lung Opacity\",\n",
    "        \"Lung Lesion\",\n",
    "        \"Edema\",\n",
    "        \"Consolidation\",\n",
    "        \"Pneumonia\",\n",
    "        \"Atelectasis\",\n",
    "        \"Pneumothorax\",\n",
    "        \"Pleural Effusion\",\n",
    "        \"Pleural Other\",\n",
    "        \"Fracture\",\n",
    "        \"Support Devices\",\n",
    "    ]\n",
    "\n",
    "    split_ratio = [0.8, 0.1, 0.1]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedpath,\n",
    "        csvpath,\n",
    "        metacsvpath,\n",
    "        report_folder=None,\n",
    "        views=[\"PA\"],\n",
    "        data_aug=None,\n",
    "        seed=0,\n",
    "        unique_patients=True,\n",
    "        mode=\"train\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.pathologies = sorted(self.pathologies)\n",
    "        self.mode = mode\n",
    "        self.embedpath = embedpath\n",
    "        self.report_folder = report_folder\n",
    "        self.data_aug = data_aug\n",
    "        self.csv = pd.read_csv(csvpath)\n",
    "        self.metacsv = pd.read_csv(metacsvpath)\n",
    "\n",
    "        self.csv = self.csv.set_index([\"subject_id\", \"study_id\"])\n",
    "        self.metacsv = self.metacsv.set_index([\"subject_id\", \"study_id\"])\n",
    "        self.csv = self.csv.join(self.metacsv).reset_index()\n",
    "\n",
    "        self.csv[\"view\"] = self.csv[\"ViewPosition\"]\n",
    "        self.limit_to_selected_views(views)\n",
    "\n",
    "        if unique_patients:\n",
    "            self.csv = self.csv.groupby(\"subject_id\").first().reset_index()\n",
    "\n",
    "        n_row = self.csv.shape[0]\n",
    "        if self.mode == \"train\":\n",
    "            self.csv = self.csv[: int(n_row * self.split_ratio[0])]\n",
    "        elif self.mode == \"valid\":\n",
    "            self.csv = self.csv[\n",
    "                int(n_row * self.split_ratio[0]) : int(n_row * (self.split_ratio[0] + self.split_ratio[1]))\n",
    "            ]\n",
    "        elif self.mode == \"test\":\n",
    "            self.csv = self.csv[-int(n_row * self.split_ratio[-1]) :]\n",
    "        elif self.mode == \"all\" or self.mode is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"attr:mode must be one of ['train', 'valid', 'test', 'all', None], but got {self.mode}\")\n",
    "\n",
    "        healthy = self.csv[\"No Finding\"] == 1\n",
    "        labels = []\n",
    "        for pathology in self.pathologies:\n",
    "            if pathology in self.csv.columns:\n",
    "                self.csv.loc[healthy, pathology] = 0\n",
    "                mask = self.csv[pathology]\n",
    "                labels.append(mask.values)\n",
    "        self.labels = np.asarray(labels).T.astype(np.float32)\n",
    "        self.labels[self.labels == -1] = np.nan\n",
    "\n",
    "        self.pathologies = list(np.char.replace(self.pathologies, \"Pleural Effusion\", \"Effusion\"))\n",
    "        self.csv[\"offset_day_int\"] = self.csv[\"StudyDate\"]\n",
    "        self.csv[\"patientid\"] = self.csv[\"subject_id\"].astype(str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        sample[\"idx\"] = idx\n",
    "        sample[\"lab\"] = self.labels[idx]\n",
    "\n",
    "        subjectid = str(self.csv.iloc[idx][\"subject_id\"])\n",
    "        studyid = str(self.csv.iloc[idx][\"study_id\"])\n",
    "        dicom_id = str(self.csv.iloc[idx][\"dicom_id\"])\n",
    "\n",
    "        # Load image embedding\n",
    "        embed_file = os.path.join(\n",
    "            self.embedpath,\n",
    "            \"p\" + subjectid[:2],\n",
    "            \"p\" + subjectid,\n",
    "            \"s\" + studyid,\n",
    "            dicom_id + \".tfrecord\",\n",
    "        )\n",
    "        sample[\"embedding\"] = load_embedding(embed_file)\n",
    "\n",
    "        # Load report text\n",
    "        if self.report_folder:\n",
    "            report_file = os.path.join(\n",
    "                self.report_folder,\n",
    "                \"p\" + subjectid[:2],\n",
    "                \"p\" + subjectid,\n",
    "                \"s\" + studyid + \".txt\"\n",
    "            )\n",
    "            try:\n",
    "                with open(report_file, \"r\") as f:\n",
    "                    sample[\"report_text\"] = f.read()\n",
    "            except FileNotFoundError:\n",
    "                sample[\"report_text\"] = \"\"\n",
    "        else:\n",
    "            sample[\"report_text\"] = \"\"\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def limit_to_selected_views(self, views):\n",
    "        if type(views) is not list:\n",
    "            views = [views]\n",
    "        if \"*\" in views:\n",
    "            views = [\"*\"]\n",
    "        self.views = views\n",
    "        self.csv[\"view\"] = self.csv[\"view\"].fillna(\"UNKNOWN\")\n",
    "        if \"*\" not in views:\n",
    "            self.csv = self.csv[self.csv[\"view\"].isin(self.views)]\n",
    "\n",
    "    def string(self):\n",
    "        return f\"{self.__class__.__name__} mode={self.mode} num_samples={len(self)} views={self.views}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41840019",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedpath = \"generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/files\"\n",
    "csvpath = \"mimic-cxr-2.0.0-chexpert.csv\"\n",
    "metacsvpath = \"mimic-cxr-2.0.0-metadata.csv\"\n",
    "report_folder = \"mimic-cxr-reports/files\"\n",
    "\n",
    "dataset = MIMIC_Embed_Dataset(\n",
    "    embedpath=embedpath,\n",
    "    csvpath=csvpath,\n",
    "    metacsvpath=metacsvpath,\n",
    "    report_folder=report_folder,\n",
    "    mode=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b593bdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 45628\n",
      "Label shape: (45628, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(dataset))              # Number of samples\n",
    "print(\"Label shape:\", dataset.labels.shape)            # Label matrix shape (num_samples, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf4ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in sample: dict_keys(['idx', 'lab', 'embedding', 'report_text'])\n",
      "Embedding type: <class 'torch.Tensor'>\n",
      "Report text length: 644\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "print(\"Keys in sample:\", sample.keys())\n",
    "print(\"Embedding type:\", type(sample[\"embedding\"]))\n",
    "print(\"Report text length:\", len(sample[\"report_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f3b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: embedding shape = torch.Size([1376]), report length = 644\n",
      "Sample 1: embedding shape = torch.Size([1376]), report length = 489\n",
      "Sample 2: embedding shape = torch.Size([1376]), report length = 675\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    sample = dataset[i]\n",
    "    print(f\"Sample {i}: embedding shape = {sample['embedding'].shape}, report length = {len(sample['report_text'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset for saving: 100%|██████████| 45628/45628 [20:30<00:00, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 多模态数据已保存为 mimic_multimodal_dataset.npz\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists\n",
    "embeddings, labels, texts, subject_ids, study_ids = [], [], [], [], []\n",
    "\n",
    "for i in tqdm(range(len(dataset)), desc=\"Processing dataset for saving\"):\n",
    "    row = dataset.csv.iloc[i]\n",
    "    sample = dataset[i]\n",
    "    \n",
    "    embeddings.append(sample[\"embedding\"].numpy())\n",
    "    labels.append(sample[\"lab\"])\n",
    "    texts.append(sample[\"report_text\"])\n",
    "    subject_ids.append(row[\"subject_id\"])\n",
    "    study_ids.append(row[\"study_id\"])\n",
    "\n",
    "# Convert to arrays\n",
    "embeddings = np.array(embeddings)\n",
    "labels = np.array(labels)\n",
    "texts = np.array(texts, dtype=object)  # 文字长度不一致时需 object\n",
    "subject_ids = np.array(subject_ids)\n",
    "study_ids = np.array(study_ids)\n",
    "\n",
    "# Save as a compressed .npz file\n",
    "np.savez_compressed(\n",
    "    \"mimic_multimodal_dataset.npz\",\n",
    "    embeddings=embeddings,\n",
    "    labels=labels,\n",
    "    texts=texts,\n",
    "    subject_ids=subject_ids,\n",
    "    study_ids=study_ids\n",
    ")\n",
    "print(\"Multimodal data saved to mimic_multimodal_dataset.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"mimic_multimodal_dataset.npz\", allow_pickle=True)\n",
    "\n",
    "embeddings = data[\"embeddings\"]\n",
    "labels = data[\"labels\"]\n",
    "texts = data[\"texts\"]\n",
    "subject_ids = data[\"subject_ids\"]\n",
    "study_ids = data[\"study_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6c9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving report text: 100%|██████████| 45628/45628 [25:38<00:00, 29.65it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Collect required information\n",
    "records = []\n",
    "for i in tqdm(range(len(dataset)), desc=\"Saving report text\"):\n",
    "    row = dataset.csv.iloc[i]\n",
    "    sample = dataset[i]\n",
    "    records.append({\n",
    "        \"subject_id\": row[\"subject_id\"],\n",
    "        \"study_id\": row[\"study_id\"],\n",
    "        \"report_text\": sample[\"report_text\"]\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_text = pd.DataFrame(records)\n",
    "\n",
    "# Save as CSV file\n",
    "df_text.to_csv(\"mimic_report_text_only.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e447206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已生成 mimic_report_with_labels.csv，共 45628 条记录\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the two datasets\n",
    "df_text = pd.read_csv(\"mimic_report_text_only.csv\")\n",
    "df_chexpert = pd.read_csv(\"mimic-cxr-2.0.0-chexpert.csv\")\n",
    "\n",
    "# 2. Keep necessary columns from chexpert (primary keys + labels)\n",
    "label_columns = [\n",
    "    \"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\",\n",
    "    \"Lung Lesion\", \"Edema\", \"Consolidation\", \"Pneumonia\",\n",
    "    \"Atelectasis\", \"Pneumothorax\", \"Pleural Effusion\",\n",
    "    \"Pleural Other\", \"Fracture\", \"Support Devices\"\n",
    "]\n",
    "df_labels = df_chexpert[[\"subject_id\", \"study_id\"] + label_columns]\n",
    "\n",
    "# 3.Merge the two tables based on subject_id + study_id\n",
    "df_merged = pd.merge(df_text, df_labels, on=[\"subject_id\", \"study_id\"], how=\"inner\")\n",
    "\n",
    "# 4. Save to a new CSV file\n",
    "df_merged.to_csv(\"mimic_task2_linked_data_half.csv\", index=False)\n",
    "print(\" mimic_task2_linked_data_half.csv generated with {} records\".format(len(df_merged)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
